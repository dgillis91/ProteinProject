{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of \"Similar\" Sentences Using The Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "I'm doing a thing to generate similar protein sequences, eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.layers import Bidirectional, Dense, Embedding\n",
    "from keras.layers import Input, Lambda, LSTM, RepeatVector\n",
    "from keras.layers import Flatten, TimeDistributed, Layer\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import objectives\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Originally we were using a dataset of quora questions.\n",
    "However, it became immediately clear that the model was\n",
    "learning a single sentence which could minimize the loss\n",
    "function. So, we are trying another dataset which\n",
    "consists of Wikipedia sentences. It is worth noting that\n",
    "this dataset has not been vetted. It is also known that\n",
    "wikipedia articles contain some level of noise.\n",
    "\n",
    "The dataset consists of roughly 800,000 questions\n",
    "posted on Quora. This data was made publicly\n",
    "available via Kaggle at this \n",
    "[link](https://www.kaggle.com/quora/question-pairs-dataset).\n",
    "The original intent of this dataset was to find \n",
    "duplicate questions, but it works well for our \n",
    "purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download\n",
    "\n",
    "There are multiple ways to download the data. My\n",
    "preference is to use the kaggle API.\n",
    "\n",
    "Start by searching for the dataset\n",
    "\n",
    "```\n",
    "kaggle datasets list -s quora\n",
    "```\n",
    "\n",
    "Once you find the dataset, download it with\n",
    "\n",
    "```\n",
    "kaggle datasets download quora/question-pairs-dataset\n",
    "```\n",
    "\n",
    "This downloads a zip file. I'm working on \n",
    "Ubuntu, so I can unzip with\n",
    "\n",
    "```\n",
    "unzip question-pairs-dataset.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "\n",
    "There is a fair bit of work to be done to preprocess the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.000123, which corresponds to a distance of 705 Mly, or 216 Mpc.',\n",
       " '000webhost is a free web hosting service, operated by Hostinger.',\n",
       " '0010x0010 is a Dutch-born audiovisual artist, currently living in Los Angeles.',\n",
       " '0-0-1-3 is an alcohol abuse prevention program developed in 2004 at Francis E. Warren Air Force Base based on research by the National Institute on Alcohol Abuse and Alcoholism regarding binge drinking in college students.',\n",
       " '0.01 is the debut studio album of H3llb3nt, released on February 20, 1996 by Fifth Colvmn Records.',\n",
       " '001 of 3 February 1997, which was signed between the Government of the Republic of Rwanda, and FAPADER.',\n",
       " '003230 is a South Korean food manufacturer.',\n",
       " '0.04%Gas molecules in soil are in continuous thermal motion according to the kinetic theory of gasses, there is also collision between molecules - a random walk.',\n",
       " '0.04% of the votes were invalid.',\n",
       " '005.1999.06 is the fifth studio album by the South Korean singer and actress Uhm Jung-hwa.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path = r'/home/das-hund/PycharmProjects/autoencoders'\n",
    "data_path = os.path.join(project_path, 'data')\n",
    "sentences_path = os.path.join(data_path, 'wikisent2.txt')\n",
    "\n",
    "with open(sentences_path, 'r') as wiki_sentence_file:\n",
    "    sentences = wiki_sentence_file.read().split('\\n')\n",
    "    \n",
    "sentences[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "\n",
    "We will split the texts by new lines. \n",
    "This gives us a record for each question. Then\n",
    "we fit a tokenizer on our texts, mapping words\n",
    "to integers.\n",
    "\n",
    "We aren't limiting the number of words, yet. \n",
    "We will see how the model performs, in the \n",
    "near future. In addition, I'm not going to\n",
    "limit sequence lengths, yet. I want to see\n",
    "how long the sequences are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Analytics\n",
    "\n",
    "The easiest way to do any analysis on the \n",
    "sentences is to first fit the tokenizer on\n",
    "them. \n",
    "\n",
    "With a bit of analysis, we can see that most\n",
    "sequences have fewer than 50 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_to_index = tokenizer.word_index\n",
    "index_to_word = {\n",
    "    index: word \n",
    "    for word, index in word_to_index.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Word Count: 1526234\n"
     ]
    }
   ],
   "source": [
    "word_count = len(word_to_index)\n",
    "print(f'[+] Word Count: {word_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 20000 \n",
    "MAX_SEQ_LEN = 50 \n",
    "\n",
    "tokenizer.num_words = MAX_WORDS\n",
    "sequences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 5, 480, 1140, 4444, 236, 620, 9], [6, 5, 758, 26, 439, 148, 793, 3, 660, 721], [1058, 1058, 74, 133, 6, 14, 4254, 3985, 4624, 275, 366, 3, 286, 17, 1981, 374, 2904, 293, 533, 983, 69, 10, 255, 9, 1, 48, 491, 10, 4254, 3985, 4, 19473, 2945, 6249, 3, 130, 430], [1058, 7978, 6, 1, 323, 234, 40, 2, 43, 10, 180, 292, 423, 9, 839, 206], [2, 133, 180, 466, 23, 8, 846, 81, 1, 192, 2, 1, 603, 2, 6434, 4], [6, 5, 55, 1354, 882, 2027], [1058, 9242, 1644, 5707, 3, 2698, 20, 3, 4183, 6306, 2067, 532, 7, 1, 14922, 1240, 2, 9391, 112, 6, 24, 9340, 81, 5707, 5, 5107, 3605], [1058, 9242, 2, 1, 2038, 34, 15386], [407, 8935, 6, 1, 839, 234, 40, 9, 1, 55, 1354, 349, 4, 658, 9763]]\n",
      "[+] Max Sequence Length: 50\n",
      "[+] Word Count: 1526234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  56071., 1114504., 2048662., 1837118., 1262331.,  733341.,\n",
       "         395200.,  204563.,  104114.,   60261.]),\n",
       " array([ 0.,  5., 10., 15., 20., 25., 30., 35., 40., 45., 50.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sequences[1:10])\n",
    "\n",
    "sequence_lengths = []\n",
    "for sequence in sequences:\n",
    "    seq_len = len(sequence)\n",
    "    if seq_len <= 50:\n",
    "        sequence_lengths.append(seq_len)\n",
    "sequence_lengths = np.array(sequence_lengths)\n",
    "        \n",
    "max_seq_len = max(sequence_lengths)\n",
    "word_count = len(word_to_index)\n",
    "\n",
    "print(f'[+] Max Sequence Length: {max_seq_len}')\n",
    "print(f'[+] Word Count: {word_count}')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-addc431060bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDATA_LEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_LEN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTRAIN_LEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Shuffle the data and get train test split.\n",
    "DATA_LEN = 128000\n",
    "TRAIN_LEN = 1280\n",
    "\n",
    "sequences = np.random.shuffle(sequences)\n",
    "train_sequences = sequences[:DATA_LEN]\n",
    "test_sequences = sequences[DATA_LEN:TRAIN_LEN]\n",
    "\n",
    "# Gotta free some memory here\n",
    "del sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'[+] {len(word_to_index)} words found in {merged_questions_path}')\n",
    "\n",
    "print('[+] Word Map Subset:\\n{')\n",
    "for _, (word, index) in zip(range(40), word_to_index.items()):\n",
    "    print('\\t{}: {}'.format(word, index))\n",
    "print('\\t...\\n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_sequences = pad_sequences(\n",
    "    train_sequences, maxlen=MAX_SEQ_LEN, padding='post'\n",
    ")\n",
    "test_padded_sequences = pad_sequences(\n",
    "    test_sequences, maxlen=MAX_SEQ_LEN, padding='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(padded_sequences[0:5])\n",
    "print(padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note I'm not using the GLOVE embeddings here.\n",
    "That would make it difficult to transition this\n",
    "model to protein sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "\n",
    "def build_encoder(embedding, max_seq_len, \n",
    "                  latent_dim, intermediate_dim,\n",
    "                  epsilon_std):\n",
    "    h = Bidirectional(LSTM(\n",
    "        intermediate_dim, return_sequences=True, name='lstm_encoding_one'\n",
    "    ), merge_mode='concat', name='bidirectional_encoding_one')(embedding)\n",
    "    h = Bidirectional(LSTM(\n",
    "        intermediate_dim, return_sequences=False, name='lstm_encoding_two'\n",
    "    ), merge_mode='concat', name='bidirectional_encoding_two')(h)\n",
    "    h = Dense(\n",
    "        intermediate_dim, activation='relu', name='dense_encoding'\n",
    "    )(h)\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean_, z_log_var_ = args\n",
    "        batch_size = K.shape(z_mean_)[0]\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=epsilon_std)\n",
    "        return z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n",
    "    \n",
    "    z_mean = Dense(latent_dim, activation='linear', name='z_mean')(h)\n",
    "    z_log_var = Dense(latent_dim, activation='linear', name='z_log_var')(h)\n",
    "    \n",
    "    def vae_loss(x, x_decoded_mean):\n",
    "        x = K.flatten(x)\n",
    "        x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "        xent_loss = max_seq_len * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return xent_loss + kl_loss\n",
    "    \n",
    "    latent = Lambda(\n",
    "        sampling, output_shape=(latent_dim,), name='latent'\n",
    "    )([z_mean, z_log_var])\n",
    "    \n",
    "    return vae_loss, latent\n",
    "\n",
    "\n",
    "def build_decoder(encoded_input, intermediate_dim,\n",
    "                  token_count, max_seq_len):\n",
    "    repeated_context = RepeatVector(\n",
    "        max_seq_len, name='repeated_context'\n",
    "    )(encoded_input)\n",
    "    \n",
    "    h = LSTM(\n",
    "        intermediate_dim, return_sequences=True, name='lstm_decoding_one'\n",
    "    )(repeated_context)\n",
    "    h = LSTM(\n",
    "        intermediate_dim, return_sequences=True, name='lstm_decoding_two'\n",
    "    )(h)\n",
    "    \n",
    "    decoded = TimeDistributed(Dense(\n",
    "        token_count, activation='softmax', name='time_distributed_decoding'\n",
    "    ), name='decoded_mean')(h)\n",
    "    \n",
    "    return decoded\n",
    "    \n",
    "    \n",
    "def build_model(max_seq_len, embedding_dim, token_count,\n",
    "                batch_size, intermediate_dim, \n",
    "                latent_dim, epsilon_std=0.1):\n",
    "    # ENCODER\n",
    "    encoder_input = Input(shape=(max_seq_len,), name='encoder_input')\n",
    "    embedding = Embedding(\n",
    "        token_count, embedding_dim,\n",
    "        input_length=max_seq_len, name='embedding'\n",
    "    )(encoder_input)\n",
    "    \n",
    "    vae_loss, encoded = build_encoder(\n",
    "        embedding=embedding, max_seq_len=max_seq_len,\n",
    "        latent_dim=latent_dim, intermediate_dim=intermediate_dim,\n",
    "        epsilon_std=epsilon_std\n",
    "    )\n",
    "    \n",
    "    encoder = Model(encoder_input, encoded, name='encoder')\n",
    "    \n",
    "    # DECODER\n",
    "    encoded_input = Input(shape=(latent_dim,), name='encoded_input')\n",
    "    decoded = build_decoder(\n",
    "        encoded_input=encoded_input, intermediate_dim=intermediate_dim,\n",
    "        token_count=token_count, max_seq_len=max_seq_len\n",
    "    )\n",
    "    \n",
    "    decoder = Model(encoded_input, decoded, name='decoder')\n",
    "    \n",
    "    # VAE\n",
    "    vae = Model(\n",
    "        encoder_input, \n",
    "        build_decoder(\n",
    "            encoded_input=encoded, intermediate_dim=intermediate_dim,\n",
    "            token_count=token_count, max_seq_len=max_seq_len\n",
    "        ), \n",
    "        name='vae')\n",
    "    vae.compile(\n",
    "        optimizer='Adam',\n",
    "        loss=vae_loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return vae, encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = MAX_SEQ_LEN\n",
    "EMBED_DIM = 16\n",
    "WORD_COUNT = MAX_WORDS\n",
    "BATCH_SIZE = 128\n",
    "STEPS_PER_EPOCH=DATA_LEN // BATCH_SIZE\n",
    "INTERMEDIATE_DIM = 16\n",
    "LATENT_DIM = 8\n",
    "\n",
    "vae, encoder, decoder = build_model(\n",
    "    max_seq_len=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    token_count=WORD_COUNT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    intermediate_dim=INTERMEDIATE_DIM,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    epsilon_std=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_oh_encode(X_train, maxlen, num_words):\n",
    "    temp = np.zeros((X_train.shape[0], maxlen, num_words))\n",
    "    temp[\n",
    "        np.expand_dims(\n",
    "            np.arange(X_train.shape[0]), axis=0\n",
    "        ).reshape(\n",
    "            X_train.shape[0], 1\n",
    "        ), np.repeat(\n",
    "            np.array([np.arange(maxlen)]), X_train.shape[0], axis=0\n",
    "        ), X_train\n",
    "    ] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will need this when we get the model working.\n",
    "def batch_generator(X, batch_size, max_seq_len, num_words):\n",
    "    indices = np.arange(len(X)) \n",
    "    batch=[]\n",
    "    while True:\n",
    "        np.random.shuffle(indices) \n",
    "        for i in indices:\n",
    "            batch.append(i)\n",
    "            if len(batch)==batch_size:\n",
    "                yield X[batch], complex_oh_encode(X[batch], maxlen=max_seq_len, num_words=num_words)\n",
    "                batch=[]\n",
    "\n",
    "train_generator = batch_generator(\n",
    "    X=padded_sequences, batch_size=BATCH_SIZE,\n",
    "    max_seq_len=MAX_SEQUENCE_LENGTH,\n",
    "    num_words=WORD_COUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vae, show_shapes=True, show_layer_names=True, to_file='vae.png')\n",
    "Image(retina=True, filename='vae.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vae.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "    epochs=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = vae.predict(padded_sequences[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([\n",
    "    index_to_word[i] if i != 0 else ''\n",
    "    for i in padded_sequences[8]\n",
    "]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    pred_chars = [np.argmax(l) for l in preds[i]]\n",
    "    print(' '.join([\n",
    "        index_to_word[i] if i != 0 else '' \n",
    "        for i in pred_chars\n",
    "    ]).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
