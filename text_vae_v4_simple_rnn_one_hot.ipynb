{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of \"Similar\" Sequences Using The Recurrent Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "I'm doing a thing to generate similar protein sequences, eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# NEXT: \n",
    "# Adagrad massively outperforms adadelta.\n",
    "# Delta could likely be tuned, but y tho.\n",
    "# We do know that adagrad is going to \n",
    "# decay the LR quickly. Are we just set\n",
    "# too high? What about batch size?\n",
    "# Switch to Inheritence to use KL Annealing. \n",
    "# https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.layers import Bidirectional, Dense, Embedding\n",
    "from keras.layers import Input, Lambda, LSTM, RepeatVector\n",
    "from keras.layers import Flatten, TimeDistributed, Layer, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Activation\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import objectives\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model, get_file\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "We are working with a file that contains\n",
    "sequences. Each sequence is on a new line.\n",
    "Because of the way the sequences are pulled,\n",
    "there are additional \"-\" characters used for\n",
    "alignment. We will strip these out, and pad\n",
    "the front of the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nurl = 'https://raw.githubusercontent.com/badriadhikari'\\ndeepcon_path = 'DEEPCON/master/deepcon-covariance/test'\\nfile = '16pkA0.aln'\\nfilepath = os.path.join(url, deepcon_path, file)\\n#file = get_file(file, filepath)\\nfile = '/home/das-hund/PycharmProjects/autoencoders/data/pdb_seqres.txt'\\n\\nwith open(file, 'r') as sequence_file:\\n    sequences = sequence_file.read()                              .replace('-', '')                              .split('\\n')\\n\\nsequence_count = len(sequences)\\nprint(f'[+] {sequence_count} Sequences in {file}')\\nprint(f'[+] Subset of Sequences:')\\nprint('\\n\\n'.join(sequences[:5]))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "url = 'https://raw.githubusercontent.com/badriadhikari'\n",
    "deepcon_path = 'DEEPCON/master/deepcon-covariance/test'\n",
    "file = '16pkA0.aln'\n",
    "filepath = os.path.join(url, deepcon_path, file)\n",
    "#file = get_file(file, filepath)\n",
    "file = '/home/das-hund/PycharmProjects/autoencoders/data/pdb_seqres.txt'\n",
    "\n",
    "with open(file, 'r') as sequence_file:\n",
    "    sequences = sequence_file.read() \\\n",
    "                             .replace('-', '') \\\n",
    "                             .split('\\n')\n",
    "\n",
    "sequence_count = len(sequences)\n",
    "print(f'[+] {sequence_count} Sequences in {file}')\n",
    "print(f'[+] Subset of Sequences:')\n",
    "print('\\n\\n'.join(sequences[:5]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] 509350 Sequences in /home/das-hund/PycharmProjects/autoencoders/data/pdb_seqres.txt\n",
      "[+] Subset of Sequences:\n",
      "MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDRVKHLKTEAEMKASEDLKKHGVTVLTALGAILKKKGHHEAELKPLAQSHATKHKIPIKYLEFISEAIIHVLHSRHPGNFGADAQGAMNKALELFRKDIAAKYKELGYQG\n",
      "\n",
      "MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAAKSELDKAIGRNTNGVITKDEAEKLFNQDVDAAVRGILRNAKLKPVYDSLDAVRRAALINMVFQMGETGVAGFTNSLRMLQQKRWDEAAVNLAKSRWYNQTPNRAKRVITTFRTGTWDAYKNL\n",
      "\n",
      "MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDRFKHLKTEAEMKASEDLKKAGVTVLTALGAILKKKGHHEAELKPLAQSHATKHKIPIKYLEFISEAIIHVLHSRHPGNFGADAQGAMNKALELFRKDIAAKYKELGYQG\n",
      "\n",
      "MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNSLDAAKSELDKAIGRNTNGVITKDEAEKLFNQDVDAAVRGILRNAKLKPVYDSLDAVRRAALINMVFQMGETGVAGFTNSLRMLQQKRWDEAAVNLAKSRWYNQTPNRAKRVITTFRTGTWDAYKNL\n",
      "\n",
      "MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDRFKHLKTEAEMKASEDLKKAGVTVLTALGAILKKKGHHEAELKPLAQSHATKHKIPIKYLEFISEAIIHVLHSRHPGNFGADAQGAMNKALELFRKDIAAKYKELGYQG\n",
      "CAGATG\n",
      "\n",
      "CATTAGA\n",
      "\n",
      "TCTAATG\n",
      "\n",
      "CCATGCGCTGAC\n",
      "\n",
      "GTCAGNGCATGG\n"
     ]
    }
   ],
   "source": [
    "file = '/home/das-hund/PycharmProjects/autoencoders/data/pdb_seqres.txt'\n",
    "\n",
    "sequences = []\n",
    "iter_ = 0\n",
    "with open(file, 'r') as sequence_file:\n",
    "    for iter_, line in enumerate(sequence_file):\n",
    "        if (iter_ + 1) % 2 == 0:\n",
    "            sequences.append(line.strip())\n",
    "    \n",
    "sequence_count = len(sequences)\n",
    "print(f'[+] {sequence_count} Sequences in {file}')\n",
    "print(f'[+] Subset of Sequences:')\n",
    "print('\\n\\n'.join(sequences[:5]))\n",
    "print('\\n\\n'.join(sequences[-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "\n",
    "After splitting the texts by new lines, we\n",
    "want to map the characters to integers. Note\n",
    "that we use the `char_level` argument to \n",
    "tokenize characters instead of words. \n",
    "\n",
    "Fortunately, we don't need to limit the \n",
    "number of tokens. There aren't many amino\n",
    "acids available. Worth noting, the last \n",
    "layer is currently one hot encoded. This\n",
    "is **absolutely** worth optimizing; \n",
    "however, time is a factor. \n",
    "\n",
    "We will also pad the sequences. To start,\n",
    "we also won't be limiting sequence length.\n",
    "I'll do some simple analysis to get a\n",
    "distribution of sequence length. This will\n",
    "give us an idea of whether it's worth\n",
    "limiting the length. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "word_to_index = tokenizer.word_index\n",
    "index_to_word = {\n",
    "    index: word \n",
    "    for word, index in word_to_index.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Max Sequence Length: 5070\n",
      "[+] Word Count: 25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequence_lengths = np.array([\n",
    "    len(seq) for seq in sequences\n",
    "])\n",
    "\n",
    "max_seq_len = max(sequence_lengths)\n",
    "word_count = len(word_to_index)\n",
    "\n",
    "print(f'[+] Max Sequence Length: {max_seq_len}')\n",
    "print(f'[+] Word Count: {word_count}')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(sequence_lengths)\n",
    "\n",
    "# ToDo: Update the names of these params.\n",
    "MAX_WORDS = word_count\n",
    "MAX_SEQ_LEN = 256#max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] 25 words found in /home/das-hund/PycharmProjects/autoencoders/data/pdb_seqres.txt\n",
      "[+] Word Map Subset:\n",
      "{\n",
      "\ta: 1\n",
      "\tl: 2\n",
      "\tg: 3\n",
      "\tv: 4\n",
      "\te: 5\n",
      "\ts: 6\n",
      "\tk: 7\n",
      "\tt: 8\n",
      "\ti: 9\n",
      "\td: 10\n",
      "\tr: 11\n",
      "\tp: 12\n",
      "\tn: 13\n",
      "\tf: 14\n",
      "\tq: 15\n",
      "\ty: 16\n",
      "\th: 17\n",
      "\tc: 18\n",
      "\tm: 19\n",
      "\tw: 20\n",
      "\tu: 21\n",
      "\tx: 22\n",
      "\tz: 23\n",
      "\tb: 24\n",
      "\to: 25\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f'[+] {len(word_to_index)} words found in {file}')\n",
    "\n",
    "print('[+] Word Map Subset:\\n{')\n",
    "for acid, index in word_to_index.items():\n",
    "    print('\\t{}: {}'.format(acid, index))\n",
    "print('}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Subset\n",
    "\n",
    "When training the RNNS, we will need to limit the\n",
    "length of the data to a multiple of what our batch\n",
    "size will be. In the future, we will also perform \n",
    "the train test split here. But, for now, we just\n",
    "select a random subset of the data. This will serve\n",
    "as our development set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LEN = 25600 #102400 #486400\n",
    "np.random.shuffle(sequences)\n",
    "sequences = sequences[:DATA_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ... 14  9 15]\n",
      " [ 0  0  0 ... 17  8 12]\n",
      " [ 0  0  0 ... 14 14 10]\n",
      " [17  6  1 ...  4  6 15]\n",
      " [ 0  0  0 ... 20 10 10]]\n",
      "(25600, 256)\n"
     ]
    }
   ],
   "source": [
    "print(padded_sequences[0:5])\n",
    "print(padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note I'm not using the GLOVE embeddings here.\n",
    "That would make it difficult to transition this\n",
    "model to protein sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Fix annealing rate\n",
    "rate = K.variable(0.0, name='KL_Annealing')\n",
    "annealing_rate = 0.0001\n",
    "\n",
    "\n",
    "def build_encoder(encoder_input, max_seq_len, \n",
    "                  latent_dim, intermediate_dim,\n",
    "                  epsilon_std):\n",
    "    #h = keras.layers.Masking(input_shape=(max_seq_len, token_count))(encoder_input)\n",
    "    h = Bidirectional(LSTM(\n",
    "        intermediate_dim, return_sequences=True, name='lstm_encoding_one'\n",
    "    ), merge_mode='concat', name='bidirectional_encoding_one')(encoder_input)\n",
    "    h = Bidirectional(LSTM(\n",
    "        intermediate_dim // 2, return_sequences=False, name='lstm_encoding_two'\n",
    "    ), merge_mode='concat', name='bidirectional_encoding_two')(h)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean_, z_log_var_ = args\n",
    "        batch_size = K.shape(z_mean_)[0]\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=epsilon_std)\n",
    "        return z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n",
    "    \n",
    "    z_mean = Dense(latent_dim, activation='linear', name='z_mean')(h)\n",
    "    z_log_var = Dense(latent_dim, activation='linear', name='z_log_var')(h)\n",
    "    \n",
    "    \n",
    "    # Added Rate - removed max_seq_len from xent_loss\n",
    "    # Removing annealing rate and just doing this training\n",
    "    # in groups, modifying the weight of the kl.\n",
    "    def vae_loss(x, x_decoded_mean):\n",
    "        global rate\n",
    "        global annealing_rate\n",
    "        x = K.flatten(x)\n",
    "        x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "        xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - rate * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        rate = K.tf.assign(rate, annealing_rate)\n",
    "        annealing_rate *= 1.05\n",
    "        rate = K.tf.assign(rate, K.clip(rate, 0.0, 1.0))\n",
    "        return xent_loss + kl_loss\n",
    "    \n",
    "    \n",
    "    # Custom Losses\n",
    "    def kl_divergence(x, x_decoded_mean):\n",
    "        x = K.flatten(x)\n",
    "        x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "        kl_loss = K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return kl_loss\n",
    "    \n",
    "    \n",
    "    latent = Lambda(\n",
    "        sampling, output_shape=(latent_dim,), name='latent'\n",
    "    )([z_mean, z_log_var])\n",
    "    \n",
    "    return vae_loss, latent, kl_divergence\n",
    "\n",
    "\n",
    "def build_decoder(encoded_input, intermediate_dim,\n",
    "                  token_count, max_seq_len):\n",
    "    repeated_context = RepeatVector(\n",
    "        max_seq_len, name='repeated_context'\n",
    "    )(encoded_input)\n",
    "    \n",
    "    h = LSTM(\n",
    "        intermediate_dim, return_sequences=True, name='lstm_decoding_one'\n",
    "    )(repeated_context)\n",
    "    h = LSTM(\n",
    "        intermediate_dim, return_sequences=True, name='lstm_decoding_two'\n",
    "    )(h)\n",
    "    \n",
    "    decoded = TimeDistributed(Dense(\n",
    "        token_count, activation='softmax', name='time_distributed_decoding'\n",
    "    ), name='decoded_mean')(h)\n",
    "    \n",
    "    return decoded\n",
    "    \n",
    "    \n",
    "def build_model(max_seq_len, embedding_dim, token_count,\n",
    "                batch_size, intermediate_dim, \n",
    "                latent_dim, epsilon_std=0.1):\n",
    "    # ENCODER\n",
    "    encoder_input = Input(shape=(max_seq_len, token_count), name='encoder_input')\n",
    "    \n",
    "    vae_loss, encoded, kld = build_encoder(\n",
    "        encoder_input=encoder_input, max_seq_len=max_seq_len,\n",
    "        latent_dim=latent_dim, intermediate_dim=intermediate_dim,\n",
    "        epsilon_std=epsilon_std\n",
    "    )\n",
    "    \n",
    "    encoder = Model(encoder_input, encoded, name='encoder')\n",
    "    \n",
    "    # DECODER\n",
    "    encoded_input = Input(shape=(latent_dim,), name='encoded_input')\n",
    "    decoded = build_decoder(\n",
    "        encoded_input=encoded_input, intermediate_dim=intermediate_dim,\n",
    "        token_count=token_count, max_seq_len=max_seq_len\n",
    "    )\n",
    "    \n",
    "    decoder = Model(encoded_input, decoded, name='decoder')\n",
    "\n",
    "\n",
    "    def cross_ent_loss(x, x_decoded_mean):\n",
    "        x = K.flatten(x)\n",
    "        x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "        xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "        return xent_loss\n",
    "    \n",
    "    \n",
    "    def current_annealing(x, x_d):\n",
    "        global rate\n",
    "        return rate\n",
    "    \n",
    "    \n",
    "    # VAE\n",
    "    vae = Model(\n",
    "        encoder_input, \n",
    "        build_decoder(\n",
    "            encoded_input=encoded, intermediate_dim=intermediate_dim,\n",
    "            token_count=token_count, max_seq_len=max_seq_len\n",
    "        ), \n",
    "        name='vae')\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        kld,\n",
    "        cross_ent_loss,\n",
    "        current_annealing\n",
    "    ]\n",
    "    # Trying to see if we are getting stuck in a local min\n",
    "    #sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    vae.compile(\n",
    "        optimizer='adagrad',\n",
    "        loss=vae_loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    return vae, encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = MAX_SEQ_LEN\n",
    "EMBED_DIM = 4\n",
    "WORD_COUNT = MAX_WORDS + 1\n",
    "BATCH_SIZE = 128\n",
    "STEPS_PER_EPOCH = DATA_LEN // BATCH_SIZE\n",
    "INTERMEDIATE_DIM = 16\n",
    "LATENT_DIM = 13\n",
    "EPOCHS = 22\n",
    "\n",
    "reload_model = False\n",
    "        \n",
    "vae, encoder, decoder = build_model(\n",
    "    max_seq_len=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    token_count=WORD_COUNT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    intermediate_dim=INTERMEDIATE_DIM,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    epsilon_std=0.1\n",
    ")\n",
    "\n",
    "if reload_model:\n",
    "    vae.load_weights('old_bestmodel.weights.kla.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_oh_encode(X_train, maxlen, num_words):\n",
    "    temp = np.zeros((X_train.shape[0], maxlen, num_words))\n",
    "    temp[\n",
    "        np.expand_dims(\n",
    "            np.arange(X_train.shape[0]), axis=0\n",
    "        ).reshape(\n",
    "            X_train.shape[0], 1\n",
    "        ), np.repeat(\n",
    "            np.array([np.arange(maxlen)]), X_train.shape[0], axis=0\n",
    "        ), X_train\n",
    "    ] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(vae, show_shapes=True, show_layer_names=True, to_file='vae.png')\n",
    "Image(retina=True, filename='vae.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will need this when we get the model working.\n",
    "def batch_generator(X, batch_size, max_seq_len, num_words):\n",
    "    indices = np.arange(len(X)) \n",
    "    batch=[]\n",
    "    while True:\n",
    "        np.random.shuffle(indices) \n",
    "        for i in indices:\n",
    "            batch.append(i)\n",
    "            if len(batch)==batch_size:\n",
    "                #train = X[batch].reshape((batch_size, max_seq_len, 1))\n",
    "                train_y = complex_oh_encode(X[batch], maxlen=max_seq_len, num_words=num_words)\n",
    "                yield train_y, train_y\n",
    "                batch=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/das-hund/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/22\n",
      "25600/25600 [==============================] - 169s 7ms/step - loss: 0.1356 - acc: 0.3200 - kl_divergence: -1.0759 - cross_ent_loss: 0.1355 - current_annealing: 1.0000e-04\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.31997, saving model to bestmodel.weights.kla.hdf5\n",
      "Epoch 2/22\n",
      "25600/25600 [==============================] - 166s 6ms/step - loss: 0.1293 - acc: 0.3368 - kl_divergence: -0.7454 - cross_ent_loss: 0.1292 - current_annealing: 1.0000e-04\n",
      "\n",
      "Epoch 00002: acc improved from 0.31997 to 0.33677, saving model to bestmodel.weights.kla.hdf5\n",
      "Epoch 3/22\n",
      " 5888/25600 [=====>........................] - ETA: 2:07 - loss: 0.1257 - acc: 0.3382 - kl_divergence: -0.7151 - cross_ent_loss: 0.1257 - current_annealing: 1.0000e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2b950fda48f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/notebook/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/notebook/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/notebook/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/notebook/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: One Hot the inputs\n",
    "fit_on_generator = False\n",
    "fit_model = True\n",
    "\n",
    "if fit_model:\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'bestmodel.weights.kla.hdf5', monitor='acc',\n",
    "        verbose=1, save_best_only=True, mode='max'\n",
    "    )\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='acc', patience=3, \n",
    "        min_lr=0.0001, verbose=1\n",
    "    )\n",
    "    callbacks_list = [checkpoint, reduce_lr]\n",
    "    if not fit_on_generator:\n",
    "        train = complex_oh_encode(padded_sequences, MAX_SEQ_LEN, WORD_COUNT)       \n",
    "        history = vae.fit(\n",
    "            train, train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=callbacks_list\n",
    "        )\n",
    "    else:\n",
    "        train_generator = batch_generator(\n",
    "            X=padded_sequences, batch_size=BATCH_SIZE,\n",
    "            max_seq_len=MAX_SEQUENCE_LENGTH,\n",
    "            num_words=WORD_COUNT\n",
    "        )\n",
    "        history = vae.fit_generator(\n",
    "            train_generator, \n",
    "            steps_per_epoch=STEPS_PER_EPOCH, \n",
    "            epochs=EPOCHS,\n",
    "            callbacks=callbacks_list\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        train = complex_oh_encode(padded_sequences, MAX_SEQ_LEN, WORD_COUNT)\n",
    "        for idx_sample, sample in enumerate(train):\n",
    "            for idx_seq_elem, seq_elem in enumerate(sample):\n",
    "                if seq_elem[0] == 1:\n",
    "                    train[idx_sample, idx_seq_elem, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! This won't work. \n",
    "predictors = padded_sequences.reshape((DATA_LEN, 256, 1))\n",
    "preds = vae.predict(predictors[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([\n",
    "    index_to_word[i] if i != 0 else ''\n",
    "    for i in padded_sequences[5]\n",
    "]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    pred_chars = [np.argmax(l) for l in preds[i]]\n",
    "    print(' '.join([\n",
    "        index_to_word[i] if i != 0 else '' \n",
    "        for i in pred_chars\n",
    "    ]).strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae.save('vae.h5')\n",
    "#encoder.save('encoder.h5')\n",
    "#decoder.save('decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
